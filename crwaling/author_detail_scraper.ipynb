{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cloudscraper\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1643171758355,
     "user": {
      "displayName": "Chung Ching Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13376823771419181326"
     },
     "user_tz": -480
    },
    "id": "FmlsKYXrJa4q",
    "outputId": "dd99b5ca-9ae6-4437-ec69-c82f98645f71"
   },
   "outputs": [],
   "source": [
    "def scrap():\n",
    "    authors = [] #store the song names\n",
    "    detail = []\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "    for j in tqdm(range(1, 3000)): #51186\n",
    "        try:\n",
    "            url = \"https://www.yes24.com/24/AuthorFile/Author/\"+str(j)\n",
    "            r= scraper.get(url)\n",
    "            soup=BeautifulSoup(r.text,\"html.parser\")\n",
    "\n",
    "            #start extracting info\n",
    "            #all info are inside <tbody> </tbody>\n",
    "            #inside <tbody>, EACH song is encapsulated in a <tr></tr>\n",
    "            #inside <tr>,  the song name and singer is encapsulated inside <td class=\"chart-table-track\">: <strong> encapsulates the song name\n",
    "                                                               #   <span> encapsulates the singer\n",
    "            #inside <tr>,  <td class_=\"chart-table-streams\"> stores the streams \n",
    "            authors.append(soup.select_one('#wrapperContent span:nth-child(1)').text)\n",
    "            whole_table = soup.select('table[width=\"150\"] td[height=\"20\"]')\n",
    "\n",
    "            ls = []\n",
    "            for i in whole_table:\n",
    "                ls.append(i.text)\n",
    "            detail.append(ls)\n",
    "\n",
    "        except:\n",
    "            authors.append('')\n",
    "            detail.append(['','','','',''])\n",
    "        \n",
    "    return authors,detail\n",
    "\n",
    "\n",
    "##########################################\n",
    "#put the result into a csv file\n",
    "##########################################\n",
    "# data = scrap(weeks)\n",
    "# df = pd.DataFrame(np.column_stack(data),columns=['date','song','singer','streams','url_list'])\n",
    "# df.to_csv('2022_kr.csv',index=False)\n",
    "# print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tPwixNrqyr0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▋                                                                     | 368/2999 [01:28<10:31,  4.17it/s]"
     ]
    }
   ],
   "source": [
    "data = scrap()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "spotify_chart_weekly_scraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
